# åŸºäº LSTM çš„åˆ†å±‚å¼ºåŒ–å­¦ä¹ è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿ

## ğŸ“‹ é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®å®ç°äº†åˆ†å±‚å¼æ·±åº¦å¼ºåŒ–å­¦ä¹ å†³ç­–æ¶æ„(HDRL)ï¼Œä½¿ç”¨ LSTM ç½‘ç»œè¿›è¡Œè‡ªåŠ¨é©¾é©¶çš„è½¨è¿¹è§„åˆ’ä¸è·Ÿè¸ªã€‚æœ€ç»ˆåœ¨300æ­¥è®­ç»ƒæƒ…å†µä¸‹è¾¾åˆ°æ”¶æ•›ã€‚

## ğŸ¬ æ¼”ç¤ºæ•ˆæœ

### åœºæ™¯1ï¼štown3å¤šè½¦åšå¼ˆ
![ç›´é“ä¿æŒ](pic/carla_lstm_g1.gif)

### åœºæ™¯2ï¼štown3è½¨è¿¹è¿½è¸ª
![é¿éšœæ¢é“](pic/carla_lstm_g2.gif)

### åœºæ™¯3ï¼štown4é«˜é€Ÿè·¯æ®µ
![å¤æ‚è·¯å†µ](pic/carla_lstm_g3.gif)



## ğŸš• è®­ç»ƒæ›²çº¿

![reward](pic\reward.png)

![train](pic\train.png)



## ğŸ—ï¸ ç½‘ç»œæ¶æ„è¯¦è§£

**æ ¸å¿ƒç‰¹æ€§ï¼š**

- ğŸ§  åŒå±‚å†³ç­–ç½‘ç»œï¼šQÂ¹ï¼ˆç¦»æ•£æ¢é“å†³ç­–ï¼‰+ QÂ²ï¼ˆè¿ç»­è½¨è¿¹åç§»ï¼‰
- ğŸ¯ 5é˜¶è´å¡å°”æ›²çº¿è½¨è¿¹è§„åˆ’ï¼ˆFrenetåæ ‡ç³»ï¼‰
- ğŸš— Pure Pursuit + PID è½¨è¿¹è·Ÿè¸ªæ§åˆ¶
- ğŸ‹ï¸ PPO å¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼ˆon-policyï¼‰
- ğŸ® CARLA 0.9.13 ä»¿çœŸç¯å¢ƒ

> tips:ä½¿ç”¨pidæ§åˆ¶å™¨æ˜¯ä¸ºäº†å…¼é¡¾è®­ç»ƒé€Ÿåº¦ï¼Œéƒ¨ç½²æ—¶ç›´æ¥å¯¼å‡ºonnxæ–‡ä»¶æ¥mpcæ§åˆ¶å™¨



**ç¥ç»ç½‘ç»œæµç¨‹å›¾ï¼š**

```mermaid
flowchart TD
%% å®šä¹‰é¢œè‰²æ ·å¼
classDef greenBox fill:#82C272,stroke:#333,stroke-width:2px,color:#000;
classDef orangeBox fill:#F6A861,stroke:#333,stroke-width:2px,color:#000;
classDef blueBox fill:#48A0D9,stroke:#333,stroke-width:2px,color:#fff;
classDef greyBox fill:#8E9296,stroke:#333,stroke-width:2px,color:#fff;
classDef pinkBox fill:#F29497,stroke:#333,stroke-width:2px,color:#000;
classDef purpleBox fill:#B19CD9,stroke:#333,stroke-width:2px,color:#fff;

%% ç¯å¢ƒè¾“å…¥
Env["CARLA Environment<br/>è½¦è¾†çŠ¶æ€ + ç¯å¢ƒæ„ŸçŸ¥"]:::greenBox
Input["Input State Sequence<br/>N Ã— 10 Ã— 18"]:::orangeBox

%% Q1 å†³ç­–åˆ†æ”¯
subgraph Q1 ["QÂ¹ ä¸Šå±‚å†³ç­– - æ¢é“è¡Œä¸º"]
    LSTM1["LSTM(18â†’64, L=1)"]:::blueBox
    FC1["FC(64â†’32â†’3)<br/>+ ReLU + Softmax"]:::greyBox
end

Goal["Goal ç¦»æ•£åŠ¨ä½œ<br/>0:å·¦æ¢é“ | 1:ä¿æŒ | 2:å³æ¢é“"]:::pinkBox

%% Q2 å†³ç­–åˆ†æ”¯
subgraph Q2 ["QÂ² ä¸‹å±‚å†³ç­– - è½¨è¿¹åç§»"]
    OneHot["Goal â†’ One-Hot(3)"]:::orangeBox
    Concat["Concat: Input(10,18) + Goal(10,3)<br/>â†’ (10, 21)"]:::orangeBox
    LSTM2["LSTM(21â†’64, L=1)"]:::blueBox
    FC2["FC(64â†’32â†’1)<br/>+ ReLU"]:::greyBox
    Gauss["Gaussian N(Î¼, ÏƒÂ²)"]:::purpleBox
end

Offset["Offset è¿ç»­åŠ¨ä½œ<br/>p_off âˆˆ [-1.8, +1.8]m"]:::pinkBox

%% è½¨è¿¹ç”Ÿæˆ
Traj["Bezier Trajectory Fitting<br/>5é˜¶è´å¡å°” | Frenetåæ ‡ç³» | 75ç‚¹"]:::orangeBox
Track["Pure Pursuit + PID<br/>è½¨è¿¹è·Ÿè¸ªæ§åˆ¶"]:::greyBox

%% æ•°æ®æµ
Env --> Input

Input --> LSTM1
LSTM1 --> FC1
FC1 --> Goal

Input -.->|Skip Connection| Concat
Goal --> OneHot
OneHot --> Concat
Concat --> LSTM2
LSTM2 --> FC2
FC2 --> Gauss
Gauss --> Offset

Goal --> Traj
Offset --> Traj
Traj --> Track

```



**ğŸ” ç½‘ç»œæ¨¡å—è¯¦è§£**
1ï¸âƒ£ è¾“å…¥å±‚ï¼ˆInput Layerï¼‰

```
ç»´åº¦ï¼š N Ã— 10 Ã— 18

N: Batch size
10: åºåˆ—é•¿åº¦ï¼ˆè¿‡å»10ä¸ªæ—¶é—´æ­¥ï¼‰
18: çŠ¶æ€ç‰¹å¾ç»´åº¦
çŠ¶æ€ç‰¹å¾ï¼ˆ18ç»´ï¼‰ï¼š

[v_ego, lane_id, Î”vâ‚, Î”vâ‚‚, ..., Î”vâ‚ˆ, Î”dâ‚, Î”dâ‚‚, ..., Î”dâ‚ˆ]
v_ego: è‡ªè½¦é€Ÿåº¦ï¼ˆm/sï¼‰
lane_id: å½“å‰è½¦é“ID
Î”vâ‚~Î”vâ‚ˆ: 8ä¸ªæ„ŸçŸ¥åŒºåŸŸçš„ç›¸å¯¹é€Ÿåº¦
Zone 1: LR (å·¦å)
Zone 2: L (å·¦ä¾§)
Zone 3: LF (å·¦å‰)
Zone 4: LS (å·¦ä¾§)
Zone 5: CF (ä¸­å‰)
Zone 6: RS (å³ä¾§)
Zone 7: RF (å³å‰)
Zone 8: RR (å³å)
Î”dâ‚~Î”dâ‚ˆ: 8ä¸ªæ„ŸçŸ¥åŒºåŸŸçš„ç›¸å¯¹è·ç¦»ï¼ˆmï¼‰
```

2ï¸âƒ£ QÂ¹ ç½‘ç»œ - æ¢é“å†³ç­–ï¼ˆDecision Model QÂ¹ï¼‰
```
åŠŸèƒ½ï¼š è¾“å‡ºç¦»æ•£çš„æ¢é“å†³ç­–

ç½‘ç»œç»“æ„ï¼š

Input (NÃ—10Ã—18) 
  â†“
LSTM (hidden_size=64, num_layers=1)
  â†“
FC1 (64 â†’ 32, ReLU)
  â†“
FC2 (32 â†’ 3)
  â†“
Softmax
  â†“
Goal âˆˆ {0: å·¦æ¢é“, 1: ä¿æŒè½¦é“, 2: å³æ¢é“}
è¾“å‡ºï¼š 3ç»´æ¦‚ç‡åˆ†å¸ƒï¼Œé‡‡æ ·å¾—åˆ°ç¦»æ•£åŠ¨ä½œ
```
3ï¸âƒ£ QÂ² ç½‘ç»œ - è½¨è¿¹åç§»ï¼ˆDecision Model QÂ²ï¼‰
```
åŠŸèƒ½ï¼š è¾“å‡ºè¿ç»­çš„æ¨ªå‘åç§»é‡

ç½‘ç»œç»“æ„ï¼š

Input (NÃ—10Ã—18) + Concat(QÂ¹ LSTM output)
  â†“
LSTM (hidden_size=64, num_layers=1)
  â†“
FC1 (64 â†’ 32, ReLU)
  â†“
FC2 (32 â†’ 3)
  â†“
Softmax â†’ Offset
  â†“
Offset âˆˆ [-1.8, +1.8] meters
è¾“å‡ºï¼š è¿ç»­å®æ•°ï¼Œè¡¨ç¤ºåœ¨ Goal åŸºç¡€ä¸Šçš„ç²¾ç»†è°ƒæ•´

æ­£å€¼ï¼šå‘å³åç§»
è´Ÿå€¼ï¼šå‘å·¦åç§»
```
4ï¸âƒ£ è½¨è¿¹ç”Ÿæˆæ¨¡å—ï¼ˆTrajectory Fittingï¼‰
```
è¾“å…¥ï¼š Goalï¼ˆç¦»æ•£ï¼‰+ Offsetï¼ˆè¿ç»­ï¼‰

å¤„ç†æµç¨‹ï¼š

graph LR
    A[Goal + Offset] --> B[è®¡ç®—ç›®æ ‡ Frenet åæ ‡<br/>df = dâ‚€ Â± lane_width + offset]
    B --> C[5é˜¶è´å¡å°”æ›²çº¿æ‹Ÿåˆ<br/>6ä¸ªæ§åˆ¶ç‚¹]
    C --> D[Frenet â†’ Cartesian<br/>åæ ‡è½¬æ¢]
    D --> E[æ™ºèƒ½ç¢°æ’æˆªæ–­<br/>OBBé¢„æµ‹]
    E --> F[Reference Trajectory<br/>75ä¸ªé‡‡æ ·ç‚¹]
5é˜¶è´å¡å°”æ§åˆ¶ç‚¹ï¼š

Pâ‚€ = dâ‚€  (èµ·ç‚¹æ¨ªå‘åç§»)
Pâ‚ = dâ‚€  (ä¿è¯ d'(0) = 0)
Pâ‚‚ = dâ‚€  (ä¿è¯ d''(0) = 0)
Pâ‚ƒ = df  (ä¿è¯ d''(1) = 0)
Pâ‚„ = df  (ä¿è¯ d'(1) = 0)
Pâ‚… = df  (ç»ˆç‚¹æ¨ªå‘åç§»)

```

# ğŸš€ å¿«é€Ÿå¼€å§‹

**ç¯å¢ƒè¦æ±‚**

```
ç¯å¢ƒè¦æ±‚
Python 3.7
CARLA 0.9.13
PyTorch 1.10+
NumPy, Gym, Pygame
```

**è®­ç»ƒæ¨¡å‹**

**1. å¯åŠ¨ CARLA æœåŠ¡å™¨**
D:\CARLA_0.9.13\WindowsNoEditor\CarlaUE4.exe -RenderOffScreen

**2. æ¿€æ´»ç¯å¢ƒ**
conda activate carla_rl

**3. å¼€å§‹è®­ç»ƒ**
cd gym-carla
python train_hierarchical.py

**4. æ–­ç‚¹ç»­è®­**
python train_hierarchical.py --resume checkpoints/policy_iter300.pth
æµ‹è¯•æ¨¡å‹
**æ ‡å‡†æµ‹è¯•ï¼ˆ20ä¸ªepisodeï¼‰**
python test_hierarchical.py --ckpt checkpoints/best_policy.pth --episodes 20

**å›°éš¾æ¨¡å¼ï¼ˆæ›´å¤šéšœç¢ç‰©ï¼‰**
python test_hierarchical_hard.py --ckpt checkpoints/final_policy.pth --episodes 5

**TensorBoard ç›‘æ§**
tensorboard --logdir=runs
æµè§ˆå™¨è®¿é—® http://localhost:6006
